bundle:
  name: wine_quality

artifacts:
  default:
    type: whl
    build: uv build
    path: .

variables:
  git_sha:
    description: git_sha
    default: abcd
  branch:
    description: branch
    default: week4
  schedule_pause_status:
    description: schedule pause status
    default: UNPAUSED
  cluster_id:
    description: Cluster ID
    default: ""

resources:
  jobs:
    wine-quality:
      name: wine-quality-workflow-test-demo
      schedule:
        quartz_cron_expression: "0 0 6 ? * MON"
        timezone_id: "Europe/Amsterdam"
        pause_status: ${var.schedule_pause_status}
      tags:
        project_name: "wine-quality"

      tasks:
        - task_key: "preprocessing"
          existing_cluster_id: ${var.cluster_id} # Use the existing cluster ID
          spark_python_task:
            python_file: "scripts/01.process_data.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
          # Removed libraries from here
        - task_key: "train_model"
          existing_cluster_id: ${var.cluster_id} # Use the existing cluster ID
          depends_on:
            - task_key: "preprocessing"
          spark_python_task:
            python_file: "scripts/02.train_register_fe_model.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
              - "--git_sha"
              - ${var.git_sha}
              - "--job_run_id"
              - "{{job.id}}"
              - "--branch"
              - ${var.branch}
          # Removed libraries from here
        - task_key: model_updated
          condition_task:
            op: "EQUAL_TO"
            left: "{{tasks.train_model.values.model_updated}}"
            right: "1"
          depends_on:
            - task_key: "train_model"
        - task_key: "deploy_model"
          depends_on:
            - task_key: "model_updated"
              outcome: "true"
          existing_cluster_id: ${var.cluster_id} # Use the existing cluster ID
          spark_python_task:
            python_file: "scripts/03.deploy_model.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
          # Removed libraries from here

targets:
  dev:
    cluster_id: 0228-114649-3khm4mcp # Existing cluster ID for dev
    default: true
    mode: development
    workspace:
      host: https://dbc-4894232b-9fc5.cloud.databricks.com
      root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED
    environment:
      libraries:
        - whl: ./dist/*.whl # Specify libraries at the environment level

  acc:
    workspace:
      host: https://dbc-4894232b-9fc5.cloud.databricks.com
      root_path: /Shared/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED
    environment:
      libraries:
        - whl: ./dist/*.whl # Specify libraries at the environment level

  prd:
    workspace:
      host: https://dbc-4894232b-9fc5.cloud.databricks.com
      root_path: /Shared/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: UNPAUSED
    environment:
      libraries:
        - whl: ./dist/*.whl # Specify libraries at the environment level
